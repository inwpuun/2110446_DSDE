{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSigx26OuY3K"
      },
      "source": [
        "# Assignment: Preparing Data for Analysis (Modified Titanic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGEv03EbuY3R"
      },
      "source": [
        "![](https://github.com/kaopanboonyuen/2110446_DataScience_2021s2/raw/main/%20files/hw.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ENNw4KZRuY3S"
      },
      "outputs": [],
      "source": [
        "#Import the libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "9EUsBCyTuY3U"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://github.com/kaopanboonyuen/2110446_DataScience_2021s2/raw/main/datasets/hw/titanic_training_dataset_v2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vT-vilTxuY3V",
        "outputId": "feac92e8-34a0-4c7b-e52d-156c867f34a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1       0.0     3.0   \n",
              "1            2       1.0     1.0   \n",
              "2            3       1.0     3.0   \n",
              "3            4       1.0     1.0   \n",
              "4            5       0.0     3.0   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0    1.0   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0    0.0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0    1.0   \n",
              "4                           Allen, Mr. William Henry    male  35.0    0.0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQkJzKJGuY3W",
        "outputId": "496cf06d-f308-4c9a-832c-0acce770f29d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['S', 'C', 'Q', nan], dtype=object)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Embarked\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat ['C' 'Q' 'S' nan]\n",
            "     Embarked_C  Embarked_Q  Embarked_S  Embarked_nan\n",
            "0           0.0         0.0         1.0           0.0\n",
            "1           1.0         0.0         0.0           0.0\n",
            "2           0.0         0.0         1.0           0.0\n",
            "3           0.0         0.0         1.0           0.0\n",
            "4           0.0         0.0         1.0           0.0\n",
            "..          ...         ...         ...           ...\n",
            "886         0.0         0.0         1.0           0.0\n",
            "887         0.0         0.0         1.0           0.0\n",
            "888         0.0         0.0         1.0           0.0\n",
            "889         1.0         0.0         0.0           0.0\n",
            "890         0.0         1.0         0.0           0.0\n",
            "\n",
            "[891 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')  # this feature will be all zeros\n",
        "\n",
        "nominal_columns = [\"Embarked\"]\n",
        "enc_df = pd.DataFrame(enc.fit_transform(df[nominal_columns]).toarray())\n",
        "\n",
        "# Get category labels from the OneHotEncoder\n",
        "categories = enc.categories_[0]\n",
        "print(\"cat\", categories)\n",
        "# Set column names to enc_df based on category labels\n",
        "enc_df.columns = [f\"Embarked_{category}\" for category in categories]\n",
        "\n",
        "print(enc_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNOG5aCOrUtm"
      },
      "source": [
        "# 1) Load data & review the data\n",
        "\n",
        "<font color='blue'>Q1) What is the shape of this dataset? (rows & columns)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BAbupvyHu6W9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rows: 891\n",
            "columns: 12\n"
          ]
        }
      ],
      "source": [
        "print('rows:', df.shape[0])\n",
        "print('columns:', df.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6owE3QFLrV4V"
      },
      "source": [
        "# 2) Drop unqualified variables\n",
        "\n",
        "*   Drop variables with missing > 50%\n",
        "*   Drop categorical variables with flat values > 70% (variables with the same value in the same column)\n",
        "\n",
        "<font color='blue'>Q2) How many columns do we have left?</font>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kAgPjtvWrXe4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.dropna(thresh=(0.5) * len(df), axis=1)\n",
        "\n",
        "columns_to_drop = []\n",
        "flat_threshold = 0.7\n",
        "\n",
        "for column in df.columns:\n",
        "    unique_values_percentage = df[column].value_counts().max() / len(df[column])\n",
        "    if unique_values_percentage > flat_threshold:\n",
        "        columns_to_drop.append(column)\n",
        "\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "df.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihy7JLa8rYBP"
      },
      "source": [
        "# 3) Remove all rows with missing target (the variable \"Survived\")\n",
        "\n",
        "<font color='blue'>Q3) How many rows do we have left?</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eKkMM--nrZ2p"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "865"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.dropna(subset = ['Survived'])\n",
        "df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKF3ciZRraVu"
      },
      "source": [
        "# 4) Handle outliers \n",
        "\n",
        "For the variable “Fare”, replace outlier values with the boundary values\n",
        "\n",
        "\n",
        "*   If value < (Q1 - 1.5IQR), relace with (Q1 - 1.5IQR)\n",
        "*   If value > (Q3 + 1.5IQR), relace with (Q3 + 1.5IQR)\n",
        "\n",
        "<font color='blue'>Q4) What is the mean of “Fare” after replacing the outliers (round 2 decimal points)?</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zhglnoscrb4y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24.038996878612718"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Q1 = df['Fare'].quantile(0.25)\n",
        "Q3 = df['Fare'].quantile(0.75)\n",
        "\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "df['Fare'].apply(lambda x: lower_bound if x < lower_bound else (upper_bound if x > upper_bound else x)).mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwxCIIi_rce4"
      },
      "source": [
        "# 5) Impute missing value\n",
        "\n",
        "\n",
        "\n",
        "*   Show the number of missing values in each variable\n",
        "*   Impute missing values with mean & mode\n",
        "*   Show the number of missing values again after missing value imputation\n",
        "\n",
        "<font color='blue'>Q5) Which variable has the largest number of missing values?</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before impute missing values\n",
            "\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass          63\n",
            "Name            25\n",
            "Sex              0\n",
            "Age            172\n",
            "SibSp           33\n",
            "Ticket          39\n",
            "Fare             0\n",
            "Embarked        87\n",
            "dtype: int64\n",
            "\n",
            "after impute missing values\n",
            "\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "print(\"before impute missing values\\n\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Create a SimpleImputer object\n",
        "imputer = SimpleImputer(strategy='mean')  # You can also use 'most_frequent' for mode\n",
        "\n",
        "# Convert DataFrame to numpy array\n",
        "df_num = df[['Pclass', 'Age', 'SibSp']]\n",
        "\n",
        "# Convert the imputed numpy array back to a DataFrame\n",
        "df[['Pclass', 'Age', 'SibSp']] = pd.DataFrame(imputer.fit_transform(df_num))\n",
        "\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "df_cat = df[[ 'Name', 'Ticket', 'Embarked' ]]\n",
        "df[[ 'Name', 'Ticket', 'Embarked' ]] = pd.DataFrame(imputer.fit_transform(df_cat))\n",
        "df = df.dropna()\n",
        "\n",
        "print(\"\\nafter impute missing values\\n\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Shrce-PErd00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before impute missing values\n",
            "\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n",
            "\n",
            "after impute missing values\n",
            "\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"before impute missing values\\n\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "df[\"Pclass\"] = df[\"Pclass\"].fillna(df[\"Pclass\"].mean())\n",
        "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
        "df[\"SibSp\"] = df[\"SibSp\"].fillna(df[\"SibSp\"].mean())\n",
        "df[\"Ticket\"] = df[\"Ticket\"].fillna(df[\"Ticket\"].mode())\n",
        "df[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode())\n",
        "\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "for column in categorical_columns:\n",
        "    mode_value = df[column].mode()[0]\n",
        "    df[column].fillna(mode_value, inplace=True)\n",
        "\n",
        "print(\"\\nafter impute missing values\\n\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXXaglHereaU"
      },
      "source": [
        "# 6) Convert categorical to numeric values\n",
        "\n",
        "\n",
        "\n",
        "*   Drop the variables “Name” & “Ticket”\n",
        "*   For the variables “Sex” & “Embarked”, perform the dummy coding and drop the first level. Also, drop those original variables (“Sex” & “Embarked”)\n",
        "\n",
        "<font color='blue'>Q6) How many columns do we have?</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5XZULmsKrf4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop([\"Name\", \"Ticket\"], axis=1)\n",
        "df = pd.get_dummies(df, columns=[\"Sex\", \"Embarked\"], drop_first=True)\n",
        "df.shape[1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjsp-1jDrgg5"
      },
      "source": [
        "# 7) Partition data\n",
        "\n",
        "\n",
        "\n",
        "*   Split train/test split with stratification using 70%:30% and random seed with 12345\n",
        "*   Show a proportion between survived (1) and died (0) in all data sets (total data, train, test)\n",
        "\n",
        "<font color='blue'>Q7) What is a proportion between survived (1) and died (0) in the training data?</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2_Kz_y2erh5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion in Train dataset:\n",
            "Survived\n",
            "0.0         0.616695\n",
            "1.0         0.383305\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Proportion in Test dataset:\n",
            "Survived\n",
            "0.0         0.615079\n",
            "1.0         0.384921\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "rows of training data 587\n",
            "rows of testing data 252\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# df2 = df.dropna(subset = ['Survived'])\n",
        "# df2 = df.fillna(df.mean())\n",
        "\n",
        "# categorical_columns = df2.select_dtypes(include=['object']).columns\n",
        "# for column in categorical_columns:\n",
        "#     mode_value = df2[column].mode()[0]\n",
        "#     df2[column].fillna(mode_value, inplace=True)\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "# Perform train/test split with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=12345)\n",
        "\n",
        "# Display proportions in all datasets\n",
        "def display_proportions(data, label):\n",
        "    proportion = data.value_counts(normalize=True)\n",
        "    print(f\"Proportion in {label} dataset:\")\n",
        "    print(proportion)\n",
        "    print()\n",
        "\n",
        "# Proportions in the training dataset\n",
        "display_proportions(pd.DataFrame(y_train, columns=['Survived']), \"Train\")\n",
        "\n",
        "# Proportions in the testing dataset\n",
        "display_proportions(pd.DataFrame(y_test, columns=['Survived']), \"Test\")\n",
        "\n",
        "print('rows of training data', y_train.shape[0])\n",
        "print('rows of testing data', y_test.shape[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment2_TitanicDataPrep_ToStudent.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
